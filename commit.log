commit 6b67610076298a0a07d32366055492554e1cce8d
Merge: 07631c4 44b14cf
Author: Wang Qi <wangqi@users.noreply.github.com>
Date:   Tue Jan 20 11:15:17 2026 -0500

    Merge branch 'ml-explore:main' into main

commit 44b14cf3194961f7443cb4d836a55f43020ee3b8
Author: David Koski <46639364+davidkoski@users.noreply.github.com>
Date:   Wed Jan 14 10:14:56 2026 -0800

    fallback for finding padToken (#461)
    
    - fixes #457
    - per @rudrankriyam "It looks for explicit [PAD] token (BERT standard), falls back to EOS token ID (autoregressive models like Qwen)"
    
    this fixes e.g. nomic-ai/nomic-embed-text-v1.5

diff --git a/Tools/embedder-tool/EmbedderRuntime+Embedding.swift b/Tools/embedder-tool/EmbedderRuntime+Embedding.swift
index f78b383..1a506b8 100644
--- a/Tools/embedder-tool/EmbedderRuntime+Embedding.swift
+++ b/Tools/embedder-tool/EmbedderRuntime+Embedding.swift
@@ -46,9 +46,9 @@ extension EmbedderRuntime {
                 )
             }
 
-            guard let padToken = tokenizer.eosTokenId else {
-                throw CommandError("Could not determine a padding token from the tokenizer.")
-            }
+            // [PAD] (BERT standard), EOS (autoregressive like Qwen)
+            let padToken = tokenizer.convertTokenToId("[PAD]") ?? tokenizer.eosTokenId ?? 0
+
             let maxLength = encoded.map { $0.1.count }.max() ?? 0
 
             let padded = stacked(

commit c1198e2782886c49466ad4c921c38740425faa6e
Author: David Koski <46639364+davidkoski@users.noreply.github.com>
Date:   Wed Jan 14 09:44:15 2026 -0800

    improve handling of portrait display on iOS (#459)

diff --git a/Applications/LLMEval/ViewModels/LLMEvaluator.swift b/Applications/LLMEval/ViewModels/LLMEvaluator.swift
index a624116..63bd159 100644
--- a/Applications/LLMEval/ViewModels/LLMEvaluator.swift
+++ b/Applications/LLMEval/ViewModels/LLMEvaluator.swift
@@ -79,17 +79,18 @@ class LLMEvaluator {
 
     /// Load and return the model. Can be called multiple times; subsequent calls return the cached model.
     func load() async throws -> ModelContainer {
-        switch loadState {
-        case .idle:
-            return try await performLoad()
+        while true {
+            switch loadState {
+            case .idle:
+                return try await performLoad()
 
-        case .loading:
-            // Already loading, wait and retry
-            try await Task.sleep(nanoseconds: 100_000_000)  // 100ms
-            return try await load()
+            case .loading:
+                // Already loading, wait and retry
+                try await Task.sleep(for: .milliseconds(100))
 
-        case .loaded(let modelContainer):
-            return modelContainer
+            case .loaded(let modelContainer):
+                return modelContainer
+            }
         }
     }
 
diff --git a/Applications/LLMEval/Views/HeaderView.swift b/Applications/LLMEval/Views/HeaderView.swift
index 1b1323d..4fd2cb6 100644
--- a/Applications/LLMEval/Views/HeaderView.swift
+++ b/Applications/LLMEval/Views/HeaderView.swift
@@ -6,78 +6,112 @@ struct HeaderView: View {
     @Bindable var llm: LLMEvaluator
     @Binding var selectedDisplayStyle: ContentView.DisplayStyle
 
-    var body: some View {
-        VStack(alignment: .leading, spacing: 12) {
-            // Model info with status
-            HStack {
-                VStack(alignment: .leading, spacing: 4) {
-                    Text("Model")
-                        .font(.caption)
-                        .foregroundStyle(.secondary)
+    @Environment(\.horizontalSizeClass) var horizontalSizeClass
+
+    var status: some View {
+        // Model info with status
+        HStack {
+            VStack(alignment: .leading, spacing: 4) {
+                Text("Model")
+                    .font(.caption)
+                    .foregroundStyle(.secondary)
+
+                Text(llm.modelInfo)
+                    .font(.headline)
+                    .lineLimit(1)
+            }
+
+            Spacer()
 
-                    Text(llm.modelInfo)
-                        .font(.headline)
-                        .lineLimit(1)
+            if llm.running {
+                HStack(spacing: 8) {
+                    ProgressView()
+                        .controlSize(.small)
+                    Text("Generating...")
+                        .font(.subheadline)
+                        .foregroundStyle(.secondary)
                 }
+            }
+        }
+    }
+
+    var options: some View {
+        HStack(spacing: 24) {
+            Toggle("Tools", isOn: $llm.includeWeatherTool)
+                .toggleStyle(.switch)
+                .fixedSize()
+                .help("Enable function calling with weather, math, and time tools")
+
+            Toggle("Thinking", isOn: $llm.enableThinking)
+                .toggleStyle(.switch)
+                .fixedSize()
+                .help("Enable thinking mode (supported by Qwen3)")
+        }
+    }
+
+    var tokens: some View {
+        // Max tokens slider
+        VStack(alignment: .leading, spacing: 4) {
+            Text("Max Tokens: \(llm.maxTokens)")
+                .font(.caption)
+                .foregroundStyle(.secondary)
+
+            Slider(
+                value: Binding(
+                    get: { log2(Double(llm.maxTokens)) },
+                    set: { llm.maxTokens = Int(pow(2, $0)) }
+                ),
+                in: 10 ... 15,  // 2^10 (1024) to 2^15 (32768)
+                step: 1
+            )
+            .frame(width: 120)
+            .help("Maximum number of tokens to generate (1024-32768)")
+        }
+    }
 
-                Spacer()
+    var display: some View {
+        Picker("Display", selection: $selectedDisplayStyle) {
+            ForEach(ContentView.DisplayStyle.allCases, id: \.self) { option in
+                Text(option.rawValue.capitalized)
+                    .tag(option)
+            }
+        }
+        .pickerStyle(.segmented)
+        .labelsHidden()
+        .frame(maxWidth: 180)
+    }
 
-                if llm.running {
-                    HStack(spacing: 8) {
-                        ProgressView()
-                            .controlSize(.small)
-                        Text("Generating...")
-                            .font(.subheadline)
-                            .foregroundStyle(.secondary)
+    var body: some View {
+        if horizontalSizeClass == .compact {
+            VStack {
+                status
+                DisclosureGroup("Controls") {
+                    VStack {
+                        options
+                        HStack {
+                            tokens
+                            display
+                        }
                     }
                 }
             }
+        } else {
+            VStack(alignment: .leading, spacing: 12) {
+                status
 
-            // Controls row
-            HStack(spacing: 16) {
-                HStack(spacing: 24) {
-                    Toggle("Tools", isOn: $llm.includeWeatherTool)
-                        .toggleStyle(.switch)
-                        .fixedSize()
-                        .help("Enable function calling with weather, math, and time tools")
-
-                    Toggle("Thinking", isOn: $llm.enableThinking)
-                        .toggleStyle(.switch)
-                        .fixedSize()
-                        .help("Enable thinking mode (supported by Qwen3)")
-
-                    // Max tokens slider
-                    VStack(alignment: .leading, spacing: 4) {
-                        Text("Max Tokens: \(llm.maxTokens)")
-                            .font(.caption)
-                            .foregroundStyle(.secondary)
-
-                        Slider(
-                            value: Binding(
-                                get: { log2(Double(llm.maxTokens)) },
-                                set: { llm.maxTokens = Int(pow(2, $0)) }
-                            ),
-                            in: 10 ... 15,  // 2^10 (1024) to 2^15 (32768)
-                            step: 1
-                        )
-                        .frame(width: 120)
-                        .help("Maximum number of tokens to generate (1024-32768)")
+                // Controls row
+                HStack(spacing: 16) {
+                    HStack(spacing: 24) {
+                        options
+                        tokens
                     }
-                }
 
-                Spacer()
+                    Spacer()
 
-                Picker("Display", selection: $selectedDisplayStyle) {
-                    ForEach(ContentView.DisplayStyle.allCases, id: \.self) { option in
-                        Text(option.rawValue.capitalized)
-                            .tag(option)
-                    }
+                    display
                 }
-                .pickerStyle(.segmented)
-                .labelsHidden()
-                .frame(maxWidth: 180)
             }
+            .padding(.bottom, 12)
         }
-        .padding(.bottom, 12)
     }
 }
diff --git a/Applications/LLMEval/Views/MetricsView.swift b/Applications/LLMEval/Views/MetricsView.swift
index 9049df9..1292bc5 100644
--- a/Applications/LLMEval/Views/MetricsView.swift
+++ b/Applications/LLMEval/Views/MetricsView.swift
@@ -15,7 +15,20 @@ struct MetricsView: View {
 
     @State private var showMemoryDetails = false
 
+    @Environment(\.horizontalSizeClass) var horizontalSizeClass
+
     var body: some View {
+        if horizontalSizeClass == .compact {
+            DisclosureGroup("Statistics") {
+                stats
+                    .scaleEffect(0.8)
+            }
+        } else {
+            stats
+        }
+    }
+
+    var stats: some View {
         VStack(spacing: 12) {
             // Top row
             HStack(spacing: 12) {
